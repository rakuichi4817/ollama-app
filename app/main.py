"""ä¸€æ—¦langhainã‚’ä½¿ã‚ãšã«å®Ÿè£…"""
from collections import namedtuple

import requests
import streamlit as st

# ãƒãƒ£ãƒƒãƒˆã®ä¿å­˜å½¢å¼
Chat = namedtuple("Chat", ["role", "content"])

# ãƒšãƒ¼ã‚¸è¨­å®š
page_title = "Ollamaãƒ‡ãƒ¢ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª"
page_icon = "ğŸ"
st.set_page_config(page_title=page_title, page_icon=page_icon)

# è¡¨ç¤º
st.write(f"# {page_icon}{page_title}")
st.write("åˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡æ™‚ã€æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™")

# ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if "model_download" not in st.session_state:
    with st.spinner("ãƒ¢ãƒ‡ãƒ«æº–å‚™ä¸­"):
        requests.post(
            "http://ollama:11434/api/pull", json={"name": "llama2", "stream": False}
        )
        # 2å›ç›®ä»¥é™ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãªã„ã‚ˆã†ã«
        st.session_state.model_download = True

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
if "chat_logs" not in st.session_state:
    st.session_state.chat_logs = []


def write_chat_log(chat: Chat | None = None):
    """å˜ä¸€ã®ãƒãƒ£ãƒƒãƒˆã‚’å‡ºåŠ›ã™ã‚‹ã‹ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã™ã¹ã¦ã‚’è¡¨ç¤ºã™ã‚‹

    Notes
    -----
    å¼•æ•°ãŒãªã‘ã‚Œã°ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º

    Parameters
    ----------
    chat : Chat | None, optional
        è¡¨ç¤ºã™ã‚‹ãƒãƒ£ãƒƒãƒˆ, by default None
    """
    if chat:
        with st.chat_message(chat.role):
            st.write(chat.content)
    else:
        for chat_log in st.session_state.chat_logs:
            with st.chat_message(chat_log.role):
                st.write(chat_log.content)


# ãƒ¦ãƒ¼ã‚¶ã‚¤ãƒ³ãƒ—ãƒƒãƒˆ
prompt = st.chat_input()
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
if st.button("æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹", type="primary", use_container_width=True):
    st.session_state.chat_logs = []

if prompt:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å½¢å¼å¤‰æ›ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã¸ã®è¿½åŠ 
    user_chat = Chat("user", prompt)
    st.session_state.chat_logs.append(user_chat)
    # æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒãƒ£ãƒƒãƒˆå«ã‚€ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã®ã™ã¹ã¦ã‚’è¡¨ç¤º
    write_chat_log()

    # ollamaå´ã«æŠ•ã’ã‚‹
    messages = [chat_log._asdict() for chat_log in st.session_state.chat_logs]
    with st.spinner("ğŸ¤–è€ƒãˆä¸­"):
        response = requests.post(
            "http://ollama:11434/api/chat",
            json={"model": "llama2", "messages": messages, "stream": False},
        )
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—
        if response.status_code != 200:
            system_chat = Chat("system", "error")
        else:
            response_json = response.json()
            system_chat = Chat(
                response_json["message"]["role"], response_json["message"]["content"]
            )
    # ã‚¹ãƒ†ãƒ¼ãƒˆã¸ã®è¿½åŠ 
    st.session_state.chat_logs.append(system_chat)
    # ã‚·ã‚¹ãƒ†ãƒ ãƒãƒ£ãƒƒãƒˆã‚’è¡¨ç¤º
    write_chat_log(system_chat)
